# 模型迭代
## 默认配置
64 128 256 512
lr 1e-4

## Version1
F1 0.8515
batchsize 12 
6.89M  1.65G
34.6M  7.57G

## Version2
1. 将dim从64改成96开始
参数量直接从37 干到77
训练速度从1.5s左右干到15s左右
从不到十分钟干到仨小时
2. dim改成80
参数量53
训练速度5s 一轮一小时 训练不动没训练

## Version3
6.02M  1.58G
38M    8.37G
dim64 训练速度8s左右,参数38，参数量变化很小，速度慢了很多 1:22
1. 修改所有降通道操作，都改成先降四倍，再提两倍
2. 移除AFF融合四个D的模块，将AFF
3. 更改为可以融合边缘增强的架构，即解码器中每一层都输出一个结果，然后都计算到损失当中
4. 解码器引入LSSM，边缘增强分支两个lap+一个差异融合作为分支，融合主干
5. 修改了损失函数,使用Focal+lovasz

## Vesion4
6.01M  1.57G
38.3M  8.37G
1024 - 'f_score=0.892704126076433'
没多高，把batsize设置为大点，
1.  解码层的BN，全改成LN,因为批数12属于很小，100多的才算大，对于这么小的批数，BN适得其反
2.  卷积偏置项
3.  开头的ABconv修改
4. 主要是对V3的实现

## Version5
1024 f1 9033
1. 输出文件夹检验
2. VSSM是通用的，注意模型版本跟VSSM的对应关系
3. 修改dims为统一设置
4. 取消Lap之前的AB融合，A,B独立提取Lap

## Version6
1. 修改AFF中的激活函数
2. 修改非SSM部分所有归一为BN
3. DDB逐通道卷积替换为普通卷积，导致参数量提升至47.6M 10.24G
4. 路径问题，sys导入前缀，需要根据账号修改CODE，把models移入每个net